// Denoå‹å®šç¾©ã®å®£è¨€
declare const Deno: {
  env: {
    get(key: string): string | undefined;
  };
};

/**
 * ãƒªãƒã‚¸ãƒˆãƒªå‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼Edge Function
 * 
 * ã€å½¹å‰²ã¨æ©Ÿèƒ½ã€‘
 * - ã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ã‹ã‚‰è©•ä¾¡ã‚¸ãƒ§ãƒ–ã‚’å–å¾—ã—ã€Cloud Run Workerã«è»¢é€ã™ã‚‹
 * - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã¨ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹ã®ç›£è¦–
 * - Cloud Runæœªå¯¾å¿œæ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆåŸºæœ¬çš„ãªè©•ä¾¡çµæœç”Ÿæˆï¼‰
 * 
 * ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ã®æµã‚Œã€‘
 * 1. GET: ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆçŠ¶æ…‹ç¢ºèªï¼‰
 * 2. POST: ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã‚¸ãƒ§ãƒ–ã‚’å–å¾—ã—ã€Cloud Run Workerã§ä¸¦è¡Œå‡¦ç†
 * 3. Cloud Runå¤±æ•—æ™‚: Edge Functionå†…ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
 */
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.39.3";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers":
    "authorization, x-client-info, apikey, content-type",
};

// ãƒ¯ãƒ¼ã‚«ãƒ¼ã®å‡¦ç†çŠ¶æ…‹ã‚’ç®¡ç†ã™ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
let isProcessing = false;
let lastProcessTime = Date.now();

serve(async (req) => {
  // ã€CORSå‡¦ç†ã€‘ãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¯¾å¿œ
  if (req.method === "OPTIONS") {
    return new Response("ok", { headers: corsHeaders });
  }

  // ã€ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã€‘ãƒ¯ãƒ¼ã‚«ãƒ¼ã®å‹•ä½œçŠ¶æ…‹ã¨æœ€çµ‚å‡¦ç†æ™‚åˆ»ã‚’è¿”ã™
  if (req.method === "GET") {
    return new Response(
      JSON.stringify({
        status: "ok",
        service: "repo_worker",
        isProcessing,
        lastProcessTime: new Date(lastProcessTime).toISOString(),
        timestamp: new Date().toISOString(),
      }),
      {
        headers: { ...corsHeaders, "Content-Type": "application/json" },
        status: 200,
      }
    );
  }

  // ã€ã‚­ãƒ¥ãƒ¼å‡¦ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‘POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚¸ãƒ§ãƒ–å‡¦ç†ã‚’é–‹å§‹
  if (req.method === "POST") {
    // åŒæ™‚å®Ÿè¡Œé˜²æ­¢ - æ—¢ã«å‡¦ç†ä¸­ã®å ´åˆã¯429ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
    if (isProcessing) {
      return new Response(
        JSON.stringify({
          message: "Worker is already processing",
          isProcessing: true,
        }),
        {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
          status: 429,
        }
      );
    }

    // å‡¦ç†çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’åˆæœŸåŒ–
    isProcessing = true;
    lastProcessTime = Date.now();

    try {
      // ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã€‘ã‚µãƒ¼ãƒ“ã‚¹ãƒ­ãƒ¼ãƒ«ã§Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
      const supabaseUrl = Deno.env.get("SUPABASE_URL") ?? "";
      const supabaseServiceKey =
        Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? "";
      const supabase = createClient(supabaseUrl, supabaseServiceKey);

      // ã€å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹é€£æºã€‘Cloud Run Workerã«å…¨ã‚¸ãƒ§ãƒ–ã®ä¸€æ‹¬å‡¦ç†ã‚’ä¾é ¼
      console.log("ğŸš€ Triggering Cloud Run Worker to poll and process all jobs...");
      
      const cloudRunUrl =
        Deno.env.get("CLOUD_RUN_WORKER_URL") || "http://host.docker.internal:8080";
      const authToken = Deno.env.get("CLOUD_RUN_AUTH_TOKEN") || "";

      try {
        // Cloud Run Workerã®ãƒãƒ¼ãƒªãƒ³ã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã—
        const response = await fetch(`${cloudRunUrl}/poll`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${authToken}`,
          },
          body: JSON.stringify({}),
        });

        if (!response.ok) {
          throw new Error(
            `Cloud Run worker poll failed: ${response.status} ${response.statusText}`
          );
        }

        const result = await response.json();
        console.log("âœ… Cloud Run Worker poll response:", result);
        
        // ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã€‘Cloud Run Workerã®æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
        isProcessing = false;
        return new Response(
          JSON.stringify({
            success: true,
            message: "Cloud Run Worker polling triggered",
            result: result,
          }),
          {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
            status: 200,
          }
        );
      } catch (pollError) {
        // ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€‘Cloud Runæ¥ç¶šå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        console.error("âŒ Failed to trigger Cloud Run Worker poll:", pollError);
        
        // ãƒ¬ã‚¬ã‚·ãƒ¼ã®å˜ä¸€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        console.log("ğŸ”„ Falling back to single message processing...");
        
        return await processLegacySingleMessage(supabase);
      }
    } finally {
      isProcessing = false;
    }
  }

  return new Response(JSON.stringify({ error: "Method not allowed" }), {
    headers: { ...corsHeaders, "Content-Type": "application/json" },
    status: 405,
  });
});

// ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã€‘Cloud Runæœªå¯¾å¿œæ™‚ã®ãƒ¬ã‚¬ã‚·ãƒ¼å˜ä¸€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
async function processLegacySingleMessage(supabase: any) {
  try {
    // ã€ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—ã€‘pgmqã‚’ä½¿ç”¨ã—ã¦æœ€åˆã®1ä»¶ã‚’å–å¾—
    const { data: messages, error: readError } = await supabase.rpc(
      "pgmq_read",
      {
        queue_name: "repo_analysis_queue",
        visibility_timeout: 300, // 5åˆ†é–“ã®å¯è¦–æ€§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        qty: 1,
      }
    );

    // ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€‘ã‚­ãƒ¥ãƒ¼èª­ã¿å–ã‚Šå¤±æ•—æ™‚ã®å‡¦ç†
    if (readError) {
      console.error("Failed to read from queue:", readError);
      return new Response(
        JSON.stringify({
          error: "Failed to read from queue",
          details: readError,
        }),
        {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
          status: 500,
        }
      );
    }

    // ã‚­ãƒ¥ãƒ¼ãŒç©ºã®å ´åˆã®å‡¦ç†
    if (!messages || messages.length === 0) {
      return new Response(
        JSON.stringify({
          message: "No messages in queue",
          processed: 0,
        }),
        {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
          status: 200,
        }
      );
    }

    const message = messages[0];
    console.log("Processing message:", message.msg_id, message.message);

    // ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã€‘ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã€Œå‡¦ç†ä¸­ã€ã«æ›´æ–°
    await supabase
      .from("job_status")
      .update({
        status: "processing",
        updated_at: new Date().toISOString(),
      })
      .eq("queue_message_id", message.msg_id);

    try {
      // ã€Cloud Runé€£æºã€‘ã‚¸ãƒ§ãƒ–ã‚’Cloud Runã«è»¢é€ï¼ˆç§˜å¯†éµã¯é€ä¿¡ã›ãšï¼‰
      console.log("ğŸš€ Starting Cloud Run processing (async)");

      // Cloud Runã§ã®å‡¦ç†ã‚’éåŒæœŸã§é–‹å§‹ï¼ˆawaitã—ãªã„ï¼‰
      forwardToCloudRunWorker({
        ...message.message,
        // HTTPçµŒç”±ã§ã®ç§˜å¯†éµé€ä¿¡ã¯é¿ã‘ã€Cloud Runã§ç›´æ¥å–å¾—
        requiresSecrets: true,
      }).catch(async (error) => {
        console.error("âŒ Cloud Run processing failed:", error);
        console.log("ğŸ”„ Attempting fallback processing within Edge Function");

        try {
          // ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã€‘Edge Functionå†…ã§åŸºæœ¬çš„ãªè©•ä¾¡ã‚’å®Ÿè¡Œ
          await processFallback(message.message, supabase);
          console.log("âœ… Fallback processing completed successfully");

          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†ã¨ã—ã¦ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
          await supabase
            .from("job_status")
            .update({
              status: "completed",
              result: {
                fallback: true,
                message:
                  "Processed within Edge Function due to Cloud Run connectivity issues",
              },
              updated_at: new Date().toISOString(),
            })
            .eq("queue_message_id", message.msg_id);
        } catch (fallbackError) {
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚‚å¤±æ•—ã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†
          console.error("âŒ Fallback processing also failed:", fallbackError);
          // ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å¤±æ•—ã«æ›´æ–°
          await supabase
            .from("job_status")
            .update({
              status: "failed",
              error: `Cloud Run failed: ${error.message}. Fallback failed: ${fallbackError.message}`,
              updated_at: new Date().toISOString(),
            })
            .eq("queue_message_id", message.msg_id);
        }
      });

      // ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã€‘Cloud Runã«è»¢é€æˆåŠŸã§å³åº§ãƒ¬ã‚¹ãƒãƒ³ã‚¹
      const result = {
        success: true,
        message: "Job forwarded to Cloud Run worker",
        cloudRunProcessing: true,
      };

      // ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å®Œäº†ã«æ›´æ–°ï¼ˆCloud Runã§ã®å‡¦ç†çµæœã¯åˆ¥é€”æ›´æ–°ï¼‰
      await supabase
        .from("job_status")
        .update({
          status: "completed",
          result: result,
          updated_at: new Date().toISOString(),
        })
        .eq("queue_message_id", message.msg_id);

      // ã€ã‚­ãƒ¥ãƒ¼ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã€‘å‡¦ç†æ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å‰Šé™¤
      await supabase.rpc("pgmq_delete", {
        queue_name: "repo_analysis_queue",
        msg_id: message.msg_id,
      });

      return new Response(
        JSON.stringify({
          success: true,
          messageId: message.msg_id,
          result: result,
        }),
        {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
          status: 200,
        }
      );
    } catch (processError) {
      // ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€‘å‡¦ç†ä¸­ã®ã‚¨ãƒ©ãƒ¼å¯¾å¿œ
      console.error("Processing error:", processError);

      // ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å¤±æ•—ã«æ›´æ–°
      await supabase
        .from("job_status")
        .update({
          status: "failed",
          error:
            processError instanceof Error
              ? processError.message
              : "Unknown error",
          updated_at: new Date().toISOString(),
        })
        .eq("queue_message_id", message.msg_id);

      // å¤±æ•—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»å‹•
      await supabase.rpc("pgmq_archive", {
        queue_name: "repo_analysis_queue",
        msg_id: message.msg_id,
      });

      return new Response(
        JSON.stringify({
          error: "Processing failed",
          messageId: message.msg_id,
          details:
            processError instanceof Error
              ? processError.message
              : "Unknown error",
        }),
        {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
          status: 500,
        }
      );
    }
  } catch (error) {
    console.error("Legacy processing error:", error);
    return new Response(
      JSON.stringify({
        error: "Legacy processing failed",
        details: error instanceof Error ? error.message : "Unknown error",
      }),
      {
        headers: { ...corsHeaders, "Content-Type": "application/json" },
        status: 500,
      }
    );
  }
}

// ã€Cloud Runé€£æºé–¢æ•°ã€‘ã‚¸ãƒ§ãƒ–ã‚’Cloud Run Workerã«è»¢é€
async function forwardToCloudRunWorker(jobPayload: any) {
  const cloudRunUrl =
    Deno.env.get("CLOUD_RUN_WORKER_URL") || "http://host.docker.internal:8080";
  const authToken = Deno.env.get("CLOUD_RUN_AUTH_TOKEN") || "";

  console.log("ğŸš€ Forwarding job to Cloud Run worker:", cloudRunUrl);
  console.log("ğŸ”‘ Auth token available:", authToken ? "Yes" : "No");
  console.log("ğŸ“¦ Payload:", JSON.stringify(jobPayload, null, 2));

  try {
    // Cloud Run Workerã®/processã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ã‚¸ãƒ§ãƒ–ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’é€ä¿¡
    const response = await fetch(`${cloudRunUrl}/process`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${authToken}`,
      },
      body: JSON.stringify(jobPayload),
    });

    if (!response.ok) {
      throw new Error(
        `Cloud Run worker failed: ${response.status} ${response.statusText}`
      );
    }

    return await response.json();
  } catch (error) {
    // æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
    console.error("âŒ Fetch error details:", error);
    console.error("âŒ Cloud Run URL:", cloudRunUrl);
    console.error("âŒ Auth token length:", authToken.length);
    throw error;
  }
}

// ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†é–¢æ•°ã€‘Cloud RunãŒåˆ©ç”¨ä¸å¯æ™‚ã®åŸºæœ¬è©•ä¾¡ç”Ÿæˆ
async function processFallback(jobPayload: any, supabaseClient: any) {
  console.log("ğŸ”„ Starting fallback processing for job:", jobPayload.jobId);

  // ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å„ãƒªãƒã‚¸ãƒˆãƒªã«åŸºæœ¬çš„ãªè©•ä¾¡çµæœã‚’ä½œæˆ
  const repositories = jobPayload.repositories || [];
  const userId = jobPayload.userId;
  const jobId = jobPayload.jobId;

  for (const repository of repositories) {
    console.log(
      `ğŸ“ Creating fallback evaluation for repository: ${repository}`
    );

    // ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã€‘åŸºæœ¬çš„ãªè©•ä¾¡çµæœã‚’æŒ¿å…¥
    const { error: insertError } = await supabaseClient
      .from("evaluation_results")
      .insert({
        id: crypto.randomUUID(),
        job_id: jobId,
        user_id: userId,
        repository_name: repository,
        total_score: 50, // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¹ã‚³ã‚¢
        evaluation_data: {
          totalScore: 50,
          items: [
            {
              id: "fallback",
              name: "Fallback Evaluation",
              score: 50,
              max_score: 100,
              positives:
                "Repository registered successfully. Detailed analysis was not available due to technical limitations.",
              negatives:
                "Full analysis could not be completed. Please retry for detailed evaluation.",
            },
          ],
          overallComment:
            "This is a fallback evaluation created when the main analysis system was unavailable. The repository has been registered and can be re-analyzed later for detailed insights.",
        },
        status: "completed",
        processing_metadata: {
          fallback: true,
          processed_at: new Date().toISOString(),
          method: "edge_function_fallback",
        },
      });

    // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è©•ä¾¡ã®æŒ¿å…¥å¤±æ•—
    if (insertError) {
      console.error(
        `âŒ Failed to insert fallback evaluation for ${repository}:`,
        insertError
      );
      throw insertError;
    }

    console.log(`âœ… Fallback evaluation created for ${repository}`);
  }

  console.log("âœ… Fallback processing completed for all repositories");
}